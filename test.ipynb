{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in ./venv/lib/python3.13/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.13/site-packages (from dotenv) (1.0.1)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.13/site-packages (0.3.19)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.37)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.10)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.13/site-packages (from langchain) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in ./venv/lib/python3.13/site-packages (from langchain) (2.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Collecting langchain_openai\n",
      "  Using cached langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in ./venv/lib/python3.13/site-packages (from langchain_openai) (0.3.37)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from langchain_openai)\n",
      "  Using cached openai-1.63.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (0.3.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.58.1->langchain_openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.58.1->langchain_openai)\n",
      "  Using cached jiter-0.8.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.58.1->langchain_openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./venv/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.35->langchain_openai) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.35->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.35->langchain_openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.35->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.35->langchain_openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n",
      "Using cached langchain_openai-0.3.6-py3-none-any.whl (54 kB)\n",
      "Using cached openai-1.63.2-py3-none-any.whl (472 kB)\n",
      "Downloading tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached jiter-0.8.2-cp313-cp313-macosx_11_0_arm64.whl (309 kB)\n",
      "Downloading regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, jiter, distro, tiktoken, openai, langchain_openai\n",
      "Successfully installed distro-1.9.0 jiter-0.8.2 langchain_openai-0.3.6 openai-1.63.2 regex-2024.11.6 tiktoken-0.9.0 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install dotenv\n",
    "!pip install requests\n",
    "!pip install langchain\n",
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elephants have complex social structures and are known for their strong familial bonds. Female elephants, also known as cows, tend to live in tight matriarchal family groups, which can consist of mothers, daughters, sisters, and their young ones. The matriarch, usually the oldest and largest female, leads the group and makes decisions regarding movement, protection, and the use of resources.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Define prompt templates (no need for separate Runnable chains)\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a facts expert who knows facts about {animal}.\"),\n",
    "        (\"human\", \"Tell me {fact_count} facts.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the combined chain using LangChain Expression Language (LCEL)\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "# chain = prompt_template | model\n",
    "\n",
    "# Run the chain\n",
    "result = chain.invoke({\"animal\": \"elephant\", \"fact_count\": 1})\n",
    "\n",
    "# Output\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recruiter (Alex): Hi [Candidate Name], thanks for connecting and taking the time to chat today. How are you doing?\n",
      "\n",
      "Candidate (Jordan): Hi Alex, I’m doing well, thank you. I appreciate you reaching out, and I’m eager to learn more about the opportunities you have available.\n",
      "\n",
      "Alex: Great to hear, Jordan. To start, I’d like to introduce myself. I’m Alex from Global Talent Partners—a recruitment agency that partners with several innovative companies here in Japan and internationally. I specialize in matching talented professionals with roles that align with their career goals. Could you share a bit about your background?\n",
      "\n",
      "Jordan: Absolutely. I’ve been in software development for about seven years now. I began my career as a junior developer in Japan and gradually moved into more senior roles. Currently, I work at ABC Tech in Tokyo, where I focus on backend development and cloud integration.\n",
      "\n",
      "Alex: That’s impressive. What initially drew you to backend development and cloud technologies? Was it a gradual shift, or did you have a clear interest from the start?\n",
      "\n",
      "Jordan: It was a mix of both. Early on, I was fascinated by the challenge of solving complex technical issues, and as I learned more, I recognized how critical robust backend systems and cloud solutions are for scaling applications. This naturally steered me toward roles where I could specialize further.\n",
      "\n",
      "Alex: Excellent. Could you walk me through what a typical day looks like for you at ABC Tech? What are your key responsibilities?\n",
      "\n",
      "Jordan: Sure. My day usually starts with a team stand-up where we review progress and address any blockers. I then dive into designing system architectures, managing a small team of developers, and ensuring that our cloud deployments run smoothly. I also coordinate with product and design teams—sometimes spanning different time zones—to ensure our technical solutions align with business needs.\n",
      "\n",
      "Alex: That sounds both challenging and rewarding. How would you describe the work culture at ABC Tech, especially given the blend of local practices and international collaboration?\n",
      "\n",
      "Jordan: The culture is very collaborative. There’s a strong emphasis on teamwork and continuous improvement. At the same time, because we work on international projects, we balance traditional Japanese work ethics—like punctuality and attention to detail—with modern agile practices that promote rapid innovation and feedback.\n",
      "\n",
      "Alex: That’s great insight. Given your current experience, what’s motivating you to explore new opportunities at this stage of your career?\n",
      "\n",
      "Jordan: While I’ve had a fulfilling experience at ABC Tech, I feel I’ve reached a point where I’m ready for new challenges. I’d like a role that offers more strategic involvement in product development and the chance to work on larger-scale, innovative projects. I’m eager to expand my skill set and contribute more broadly.\n",
      "\n",
      "Alex: Understood. Considering your aspirations, what kind of role are you looking for next? Are there particular responsibilities or types of projects that interest you?\n",
      "\n",
      "Jordan: I’m interested in a role that not only involves technical execution but also allows me to influence product direction. I’d love to work on projects that leverage cutting-edge cloud technologies and agile methodologies, and I’m also looking for an environment that values mentorship—where I can both learn from seasoned professionals and share my own experience.\n",
      "\n",
      "Alex: That makes sense. Let’s talk about some practical details. Can you share your current compensation and what your salary expectations are for your next move?\n",
      "\n",
      "Jordan: Currently, I’m earning about ¥12,000,000 per year. For my next role, I’d be looking for something in the range of ¥13,500,000 to ¥15,000,000, depending on the overall benefits and responsibilities.\n",
      "\n",
      "Alex: Thanks for clarifying that. Aside from salary, are there any other factors that are particularly important to you? For instance, work location, remote work flexibility, or specific benefits?\n",
      "\n",
      "Jordan: Location is key. Since I’m based in Tokyo, I’d prefer roles located there or that offer a hybrid model, which is respectful of local business culture. I also value opportunities for professional development, a good work-life balance, and a company culture that emphasizes open communication and continuous growth.\n",
      "\n",
      "Alex: It sounds like you have a clear vision for your next move. On the topic of culture, what kind of company values or attributes do you consider essential when evaluating a new opportunity?\n",
      "\n",
      "Jordan: I really value transparency, collaboration, and a commitment to innovation. I appreciate companies that honor both traditional business practices and modern, agile thinking. A supportive environment with clear paths for career progression and regular feedback is also very important to me.\n",
      "\n",
      "Alex: Excellent. Let’s shift gears a bit—could you describe a challenging project you’ve worked on recently? What was the challenge, and how did your team overcome it?\n",
      "\n",
      "Jordan: One project that stands out involved migrating a legacy system to a cloud-based solution. The main challenge was maintaining data consistency while minimizing downtime. We tackled it by breaking the migration into phases, performing thorough testing at each stage, and keeping continuous communication with all stakeholders. The phased approach paid off, and the project was ultimately successful, reinforcing the value of agile, incremental improvements.\n",
      "\n",
      "Alex: That’s a great example. How do you typically approach problem-solving in these complex scenarios? Is there a particular methodology you rely on?\n",
      "\n",
      "Jordan: I generally blend agile methodologies with lean principles. I break challenges into smaller tasks, focus on iterative testing, and actively seek feedback throughout the process. This approach minimizes risks and often leads to innovative solutions while keeping the team aligned.\n",
      "\n",
      "Alex: Very impressive. Since you’ve collaborated with international teams, how do you manage differences in time zones and cultural expectations?\n",
      "\n",
      "Jordan: Communication is key. I make sure to schedule overlapping work hours whenever possible and use digital collaboration tools to stay in sync. Being respectful and clear about expectations has been essential in bridging cultural differences and ensuring smooth cooperation.\n",
      "\n",
      "Alex: It’s clear you have a well-rounded approach. Now, before we wrap up, do you have any questions for me about the roles I’m recruiting for, the companies I work with, or our overall process?\n",
      "\n",
      "Jordan: Yes, I do. Could you tell me more about the types of companies you’re recruiting for, particularly how their team structures work and what kind of projects I might be involved with if I join one of them?\n",
      "\n",
      "Alex: Certainly. Our agency works with a diverse portfolio of companies—from established industry leaders to innovative startups. Typically, these companies have cross-functional teams that value collaboration. They use regular stand-ups, weekly sync-ups, and even team-building activities to ensure smooth communication, whether locally or across borders. In many cases, you’ll have the opportunity to work on projects that drive digital transformation and leverage advanced cloud solutions. Additionally, there are strong mentorship programs and clear career progression paths in place.\n",
      "\n",
      "Jordan: That sounds very promising. I’m also interested in learning about the hiring process. What should I expect in terms of next steps and any technical assessments?\n",
      "\n",
      "Alex: Generally, after our initial conversation, I’ll match you with roles that fit your profile and interests. For many positions, the process involves a technical interview with a team lead, followed by additional discussions with prospective colleagues. There might be a practical assessment depending on the role. I’ll guide you through each step to ensure the process is as transparent and efficient as possible.\n",
      "\n",
      "Jordan: I appreciate the clarity, Alex. That definitely makes me feel more confident about the process.\n",
      "\n",
      "Alex: Fantastic. I think we’ve covered a lot today. Is there anything else you’d like to discuss regarding your career goals or the opportunities we might have for you?\n",
      "\n",
      "Jordan: Not at the moment. I feel well-informed, and I’m excited about exploring roles that match my aspirations. Thank you for such a thorough conversation.\n",
      "\n",
      "Alex: My pleasure, Jordan. I’ll review the details we discussed and get back to you soon with some potential matches. Thank you again for your time and for sharing your experiences.\n",
      "\n",
      "Jordan: Thank you, Alex. I appreciate the opportunity to discuss my career and explore these new possibilities with your support. I look forward to hearing from you soon.\n",
      "\n",
      "Alex: Great. Have a wonderful day, and I’ll be in touch soon!\n",
      "\n",
      "Jordan: You too, Alex. Thanks again.\n"
     ]
    }
   ],
   "source": [
    "# read text file\n",
    "filename = \"data/jordan.txt\"\n",
    "with open(filename, \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jordan has been in software development for about seven years, starting as a junior developer in Japan and progressively moving into more senior roles. Currently, Jordan works at ABC Tech in Tokyo, focusing on backend development and cloud integration. In this role, Jordan's key responsibilities include designing system architectures, managing a small team of developers, ensuring smooth cloud deployments, and coordinating with product and design teams across different time zones to align technical solutions with business needs.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "\n",
    "\n",
    "# read text file\n",
    "filename = \"data/jordan.txt\"\n",
    "with open(filename, \"r\") as file:\n",
    "    transcript = file.read()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define prompt templates (no need for separate Runnable chains)\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant who has access to {transcript}.\"),\n",
    "        (\"human\", \"Tell me about candidate's {information}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the combined chain using LangChain Expression Language (LCEL)\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "# chain = prompt_template | model\n",
    "\n",
    "# Run the chain\n",
    "result = chain.invoke({\"transcript\": transcript, \"information\": \"work history\"})\n",
    "\n",
    "# Output format \n",
    "# we need Name, Years in company, Company, Notes\n",
    "# example output:\"name\": \"jordan\", \"years\":5,\"company\":\"Tech Corp\", \"notes\":\"Strong backend development background. Recently completed cloud certification.\" \n",
    "\n",
    "\n",
    "\n",
    "# Output\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"Jordan\",\n",
      "  \"years\": 7,\n",
      "  \"company\": \"ABC Tech\",\n",
      "  \"notes\": \"Focused on backend development and cloud integration. Manages a team of developers and coordinates internationally.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Read the text file containing the chat transcript\n",
    "filename = \"data/jordan.txt\"\n",
    "with open(filename, \"r\") as file:\n",
    "    transcript = file.read()\n",
    "\n",
    "# Define prompt templates. Note how we insert {information} into the human message.\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant who has access to the following transcript: {transcript}\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"Extract the candidate's {information} details from the transcript. \"\n",
    "                \"Return the result as a JSON object with the following keys: \"\n",
    "                \"'name' (string), 'years' (integer), 'company' (string), and 'notes' (string). \"\n",
    "                \"For example: {{'name': 'jordan', 'years': 5, 'company': 'Tech Corp', \"\n",
    "                \"'notes': 'Strong backend development background. Recently completed cloud certification.'}}\"\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the combined chain using LangChain Expression Language (LCEL)\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "# Run the chain. We pass in both the transcript and the specific information (\"work history\").\n",
    "result = chain.invoke({\"transcript\": transcript, \"information\": \"work history\"})\n",
    "\n",
    "# Output the result\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"Jordan\",\n",
      "  \"job history\": [\"Current role of 7 years at ABC Tech in Tokyo focusing on backend development and cloud integration\"],\n",
      "  \"notes\": [\n",
      "    \"Strong background in software development with a specialty in backend development and cloud integration.\",\n",
      "    \"Started as a junior developer and moved into more senior roles over seven years.\",\n",
      "    \"Interested in roles with more strategic involvement in product development and larger-scale projects.\",\n",
      "    \"Looking for roles in Tokyo or hybrid models with a salary expectation of ¥13,500,000 to ¥15,000,000.\",\n",
      "    \"Values transparency, collaboration, and innovation in company culture.\",\n",
      "    \"Next steps include matching with roles that fit aspirations and scheduling potential interviews.\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Read the text file containing the chat transcript\n",
    "filename = \"data/jordan.txt\"\n",
    "with open(filename, \"r\") as file:\n",
    "    transcript = file.read()\n",
    "\n",
    "# Define prompt templates. Note how we insert {information} into the human message.\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant who has access to the following transcript: {transcript}\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"Extract the candidate's details from the transcript. \"\n",
    "                \"Please provide the following information: {info_list}.\"\n",
    "                \"For the Notes, please provide a summary of the candidate's background, and any next actions necessary.\"\n",
    "                \"Return the result as a JSON object with the following keys: \"\n",
    "                \"'name' (string), 'job history' (list of strings), 'notes' (list of strings). \"\n",
    "                \"For example: {{'name': 'jordan', 'job history': ['4 years at Tech Corp', '3 years at Data Inc'], \"\n",
    "                \"'notes': ['Strong backend development background.'], ['Recently completed cloud certification.'], ['Recommend scheduling a follow-up interview.'], ['Interviewing at Akiba Inc.']}}\"\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the combined chain using LangChain Expression Language (LCEL)\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "# Run the chain. We pass in both the transcript and the specific information (\"work history\").\n",
    "result = chain.invoke({\"transcript\": transcript, \"info_list\": \"Name, Years in company, Company, Salary, Notes\"})\n",
    "\n",
    "# Output the result\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"Michael\",\n",
      "  \"job history\": [\n",
      "    \"3 years at TechWave Solutions\",\n",
      "    \"3 years at InnoSoft\",\n",
      "    \"2 years at NextGen Innovations\"\n",
      "  ],\n",
      "  \"notes\": [\n",
      "    \"Michael has a total of eight years of experience in software development.\",\n",
      "    \"He worked as a junior developer at TechWave Solutions, focusing on web applications and legacy systems.\",\n",
      "    \"At InnoSoft, he moved into a mid-level role, working on scalable backend systems, cloud solutions, and mentoring.\",\n",
      "    \"Currently, he's a senior developer at NextGen Innovations, leading a team and working on system architecture for high-traffic applications.\",\n",
      "    \"Michael is looking for a role that offers more strategic influence and international projects.\",\n",
      "    \"He prefers positions that balance technical leadership and hands-on development.\",\n",
      "    \"He is earning ¥10,000,000 annually and is seeking a salary range between ¥11,500,000 and ¥13,000,000.\",\n",
      "    \"Michael values a collaborative, innovative work culture with opportunities for professional development and prefers roles in Osaka or with hybrid work options.\",\n",
      "    \"Next actions include matching Michael's profile with relevant opportunities and providing detailed information about potential companies and roles.\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# maybe best one so far?\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Read the text file containing the chat transcript\n",
    "filename = \"data/michael.txt\"\n",
    "with open(filename, \"r\") as file:\n",
    "    transcript = file.read()\n",
    "\n",
    "# Define prompt templates. Note how we insert {information} into the human message.\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant who has access to the following transcript: {transcript}\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"Extract the candidate's details from the transcript. \"\n",
    "                \"Please provide the following information: {info_list}.\"\n",
    "                \"For the Notes, please provide a summary of the candidate's background, and any next actions necessary.\"\n",
    "                \"Return the result as a JSON object with the following keys: \"\n",
    "                \"'name' (string), 'job history' (list of strings), 'notes' (list of strings). \"\n",
    "                \"For example: {{'name': 'jordan', 'job history': ['4 years at Tech Corp', '3 years at Data Inc'], \"\n",
    "                \"'notes': ['Strong backend development background.'], ['Recently completed cloud certification.'], ['Recommend scheduling a follow-up interview.'], ['Interviewing at Akiba Inc.']}}\"\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "    \n",
    "# Create the combined chain using LangChain Expression Language (LCEL)\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "# Run the chain. We pass in both the transcript and the specific information (\"work history\").\n",
    "result = chain.invoke({\"transcript\": transcript, \"info_list\": \"Name, Years in company, Company, Salary, Notes\"})\n",
    "\n",
    "# Output the result\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output:\n",
      "```json\n",
      "{\n",
      "  \"name\": \"Michael\",\n",
      "  \"job history\": [\n",
      "    \"3 years at TechWave Solutions\",\n",
      "    \"3 years at InnoSoft\",\n",
      "    \"2 years at NextGen Innovations\"\n",
      "  ],\n",
      "  \"notes\": [\n",
      "    \"Total of 8 years of experience in software development.\",\n",
      "    \"Started career at TechWave Solutions as a junior developer, gaining strong foundation in Java and JavaScript.\",\n",
      "    \"At InnoSoft, worked on scalable backend systems and cloud integration with AWS, with mentoring responsibility.\",\n",
      "    \"Currently a senior developer at NextGen Innovations, leading a team and contributing to system architecture and strategic planning.\",\n",
      "    \"Motivated by strategic influence and international projects, seeking roles that combine leadership and hands-on development.\",\n",
      "    \"Targeting a salary range of ¥11,500,000 to ¥13,000,000.\",\n",
      "    \"Prefers roles in Osaka or flexible hybrid working models with professional development opportunities.\",\n",
      "    \"Thrives in transparent, collaborative environments with pathways for career advancement.\",\n",
      "    \"Led a project designing microservices-based architecture using Docker and Kubernetes to handle increased user traffic.\",\n",
      "    \"Approaches problem-solving with agile methodologies, involving team collaboration.\",\n",
      "    \"Equipped to lead international collaborations due to past exposure to diverse teams.\",\n",
      "    \"Next steps involve matching with relevant opportunities at companies focusing on digital transformation and innovation.\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Error: The output is not valid JSON.\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "```json\n",
      "{\n",
      "  \"name\": \"Michael\",\n",
      "  \"job history\": [\n",
      "    \"3 years at TechWave Solutions\",\n",
      "    \"3 years at InnoSoft\",\n",
      "    \"2 years at NextGen Innovations\"\n",
      "  ],\n",
      "  \"notes\": [\n",
      "    \"Strong background in software development with eight years of experience.\",\n",
      "    \"Experience in building web applications, maintaining legacy systems, and scalable backend systems with cloud integration using AWS.\",\n",
      "    \"Currently a senior developer leading a small team, responsible for designing system architectures and implementing solutions for high-traffic applications.\",\n",
      "    \"Looking for a role that offers strategic influence and opportunities for international projects.\",\n",
      "    \"Seeks a balance between technical leadership and hands-on development in innovative and collaborative environments.\",\n",
      "    \"Current salary is around ¥10,000,000 per year, targeting a range of ¥11,500,000 to ¥13,000,000 in the next role.\",\n",
      "    \"Prefers roles in Osaka or with flexible, hybrid working models.\",\n",
      "    \"Values professional development, work-life balance, and a collaborative and innovative company culture.\",\n",
      "    \"Prepared for leadership roles with international collaboration experience.\",\n",
      "    \"Next actions: Match with opportunities that align with his career goals and provide detailed information about companies and roles.\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# # json test version (not great)\n",
    "\n",
    "# import json\n",
    "# from dotenv import load_dotenv\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain.schema.output_parser import StrOutputParser\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# # Load environment variables from .env\n",
    "# load_dotenv()\n",
    "\n",
    "# # Create a ChatOpenAI model\n",
    "# model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# # Read the text file containing the chat transcript\n",
    "# filename = \"data/michael.txt\"\n",
    "# with open(filename, \"r\") as file:\n",
    "#     transcript = file.read()\n",
    "\n",
    "# # Define prompt templates. Note how we insert {information} into the human message.\n",
    "# prompt_template = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are a helpful assistant who has access to the following transcript: {transcript}\"\n",
    "#         ),\n",
    "#         (\n",
    "#             \"human\",\n",
    "#             (\n",
    "#                 \"Extract the candidate's details from the transcript. \"\n",
    "#                 \"Please provide the following information: {info_list}.\"\n",
    "#                 \"For the Notes, please provide a summary of the candidate's background, and any next actions necessary.\"\n",
    "#                 \"Return the result as a JSON object with the following keys: \"\n",
    "#                 \"'name' (string), 'job history' (list of strings), 'notes' (list of strings). \"\n",
    "#                 \"For example: {{'name': 'jordan', 'job history': ['4 years at Tech Corp', '3 years at Data Inc'], \"\n",
    "#                 \"'notes': ['Strong backend development background.'], ['Recently completed cloud certification.'], ['Recommend scheduling a follow-up interview.'], ['Interviewing at Akiba Inc.']}}\"\n",
    "#             )\n",
    "#         ),\n",
    "#     ]\n",
    "# )\n",
    "    \n",
    "# # Create the combined chain using LangChain Expression Language (LCEL)\n",
    "# chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "# # Run the chain. We pass in both the transcript and the specific information (\"work history\").\n",
    "# # result = chain.invoke({\"transcript\": transcript, \"info_list\": \"Name, Years in company, Company, Salary, Notes\"})\n",
    "\n",
    "# # Run the chain to get the raw output.\n",
    "# raw_result = chain.invoke({\"transcript\": transcript, \"info_list\": \"Name, Years in company, Company, Salary, Notes\"})\n",
    "\n",
    "# # Print the raw output.\n",
    "# print(\"Raw Output:\")\n",
    "# print(raw_result)\n",
    "\n",
    "# # Validate that the output is valid JSON.\n",
    "# try:\n",
    "#     json_output = json.loads(raw_result)\n",
    "#     print(\"\\nValid JSON Output:\")\n",
    "#     print(json.dumps(json_output, indent=2))\n",
    "# except json.JSONDecodeError as e:\n",
    "#     print(\"\\nError: The output is not valid JSON.\")\n",
    "#     print(e)\n",
    "\n",
    "\n",
    "\n",
    "# # Output the result\n",
    "# print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate Match Analysis:\n",
      "To analyze the match between the candidate Michael and the job description provided, let's assess the key criteria and how Michael's skills and experience align with them:\n",
      "\n",
      "1. **Years of Experience**: The job requires at least 8 years of software development experience. Michael meets this requirement with 8 years of experience.\n",
      "\n",
      "2. **Backend Skills**: The job specifies strong backend skills. Michael gained experience in scalable backend systems at InnoSoft, which aligns with this requirement.\n",
      "\n",
      "3. **Cloud Solutions**: Experience with cloud solutions is essential. Michael has experience with cloud integration using AWS, which fits this criterion.\n",
      "\n",
      "4. **Leadership Experience**: Proven leadership experience is required. Michael is currently a senior developer and leads a team at NextGen Innovations, indicating relevant leadership experience.\n",
      "\n",
      "5. **Hybrid Environments**: While specific mention of hybrid environments isn't detailed in Michael's profile, his experience with cloud integration and scalable systems implies adaptability, which could extend to hybrid environments.\n",
      "\n",
      "6. **Communication Skills**: Excellent communication skills are noted in the job description. Michael's interest in roles with strategic influence, international projects, and a company environment with open communication suggests he values and likely possesses strong communication skills.\n",
      "\n",
      "7. **International Project Experience**: While Michael is prepared for leadership roles involving international collaboration, it's unclear if he has direct experience with international projects. This represents a partial match.\n",
      "\n",
      "Based on the analysis:\n",
      "\n",
      "- Michael meets the essential requirements for years of experience, backend skills, cloud solutions, and leadership.\n",
      "- His strong communication skills and adaptability could cater to hybrid environments.\n",
      "- There is a partial alignment regarding direct international project experience.\n",
      "\n",
      "Given this assessment, Michael is a strong candidate with most of the required skills and experience, but with a slight gap in proven international project experience.\n",
      "\n",
      "**Match Score: 90/100**\n"
     ]
    }
   ],
   "source": [
    "# Chain distill data part to match score part\n",
    "\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 1. Candidate Extraction Prompt\n",
    "# ------------------------------------------\n",
    "extraction_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant who has access to the following transcript: {transcript}\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"Extract the candidate's details from the transcript. \"\n",
    "                \"Please provide the following information: {info_list}.\"\n",
    "                \"For the Notes, please provide a summary of the candidate's background, and any next actions necessary.\"\n",
    "                \"Return the result as a JSON object with the following keys: \"\n",
    "                \"'name' (string), 'job history' (list of strings), 'notes' (list of strings). \"\n",
    "                \"For example: {{'name': 'jordan', 'job history': ['4 years at Tech Corp', '3 years at Data Inc'], \"\n",
    "                \"'notes': ['Strong backend development background.'], ['Recently completed cloud certification.'], ['Recommend scheduling a follow-up interview.'], ['Interviewing at Akiba Inc.']}}\"\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------\n",
    "# 2. Matching Prompt Template\n",
    "# ------------------------------------------\n",
    "matching_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a talent assessment assistant.\"),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"Below is the candidate data in JSON format:\\n{candidate_json}\\n\\n\"\n",
    "                \"And here is the job description:\\n{job_description}\\n\\n\"\n",
    "                # \"Provide a detailed analysis of how well the candidate matches the job description. \"\n",
    "                \"Analyze the candidate's skills and experience based on the job description. \"\n",
    "                # \"Include a match score between 0 and 100 (with 100 being a perfect match) along with recommendations.\"\n",
    "                \"Return a match score between 0 and 100 (with 100 being a perfect match).\"\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3. Prepare Candidate Data for Matching\n",
    "# ------------------------------------------\n",
    "# In this step, we take the candidate JSON output from the extraction chain and combine it with a job description.\n",
    "job_description_text = (\n",
    "    \"We are seeking a senior developer with strong backend skills and proven leadership experience. \"\n",
    "    \"The ideal candidate should have at least 8 years of experience in software development, \"\n",
    "    \"expertise in scalable backend systems and cloud solutions, and a track record of mentoring and leading teams. \"\n",
    "    \"Experience in hybrid environments, excellent communication skills, and international project experience are a plus.\"\n",
    ")\n",
    "\n",
    "prepare_for_matching = RunnableLambda(\n",
    "    lambda candidate_json: {\"candidate_json\": candidate_json, \"job_description\": job_description_text}\n",
    ")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 4. Build the Sequential Chain\n",
    "# ------------------------------------------\n",
    "# Here we chain together:\n",
    "#   - extraction_template -> model -> StrOutputParser()  (extract candidate JSON)\n",
    "#   - prepare_for_matching  (package candidate JSON with job description)\n",
    "#   - matching_template -> model -> StrOutputParser()  (assess candidate match)\n",
    "chain = (\n",
    "    extraction_template\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    "    | prepare_for_matching\n",
    "    | matching_template\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 5. Run the Chain with a Transcript\n",
    "# ------------------------------------------\n",
    "# Read the candidate transcript from a file\n",
    "filename = \"data/michael.txt\"\n",
    "with open(filename, \"r\") as file:\n",
    "    transcript = file.read()\n",
    "\n",
    "# Execute the sequential chain by providing the transcript.\n",
    "result = chain.invoke({\"transcript\": transcript, \"info_list\": \"Name, Years in company, Company, Salary, Notes\"})\n",
    "\n",
    "# Output the final match analysis\n",
    "print(\"Candidate Match Analysis:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"Michael\",\n",
      "  \"job history\": [\n",
      "    \"3 years at TechWave Solutions\",\n",
      "    \"3 years at InnoSoft\",\n",
      "    \"2 years at NextGen Innovations\"\n",
      "  ],\n",
      "  \"salary\": \"¥10,000,000\",\n",
      "  \"notes\": [\n",
      "    \"8 years of experience in software development.\",\n",
      "    \"Strong skills in Java and JavaScript.\",\n",
      "    \"Experience with scalable backend systems and cloud solutions using AWS.\",\n",
      "    \"Mentoring experience and leadership roles at InnoSoft and NextGen Innovations.\",\n",
      "    \"Looking for a role with strategic influence and international projects.\",\n",
      "    \"Seeks a salary range of ¥11,500,000 to ¥13,000,000.\",\n",
      "    \"Prefers hybrid work arrangements and values professional development and work-life balance.\"\n",
      "  ],\n",
      "  \"next_actions\": [\n",
      "    \"Match profile with relevant opportunities.\",\n",
      "    \"Provide detailed information about the companies and roles.\"\n",
      "  ],\n",
      "  \"match_score\": 95\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# distill + match_score in one step\n",
    "\n",
    "# maybe best one so far?\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Read the text file containing the chat transcript\n",
    "filename = \"data/michael.txt\"\n",
    "with open(filename, \"r\") as file:\n",
    "    transcript = file.read()\n",
    "\n",
    "# Define prompt templates. Note how we insert {information} into the human message.\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant who has access to the following transcript: {transcript}\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"Extract the candidate's details from the transcript. \"\n",
    "                \"Please provide the following information: {info_list}.\"\n",
    "                \"For Salary, please put their current annual salary.\"\n",
    "                \"For the Notes, please provide a summary of the candidate's background, main skills, motivations, and expected salary.\"\n",
    "                \"For Next Actions, please list exactly 2 next actions for the recruiter should do for the candidate, such as schedule follow up meeting, send job description, etc. If there is nothing to do, please write 'No next actions'.\"\n",
    "                \"Based on the above candidate details, analyze the candidate's skills and experience based on the {job_description}. \"\n",
    "                \"Return a match score between 0 and 100 (with 100 being a perfect match).\"\n",
    "                \"Return the result as a JSON object with the following keys: \"\n",
    "                \"'name' (string), 'job history' (list of strings), 'salary' (string), 'notes' (list of strings). \"\n",
    "                \"For example: {{'name': 'jordan', 'job history': ['4 years at Tech Corp', '3 years at Data Inc'], \"\n",
    "                \"'notes': ['Strong backend development background.'], ['Recently completed cloud certification.'], ['Recommend scheduling a follow-up interview.'], ['Interviewing at Akiba Inc.'], 'match_score': 85}}\"\n",
    "\n",
    "\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Job description\n",
    "job_description_text = (\n",
    "    \"We are seeking a senior developer with strong backend skills and proven leadership experience. \"\n",
    "    \"The ideal candidate should have at least 8 years of experience in software development, \"\n",
    "    \"expertise in scalable backend systems and cloud solutions, and a track record of mentoring and leading teams. \"\n",
    "    \"Experience in hybrid environments, excellent communication skills, and international project experience are a plus.\"\n",
    ")\n",
    "\n",
    "# Create the combined chain using LangChain Expression Language (LCEL)\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "# Run the chain. We pass in both the transcript and the specific information (\"work history\").\n",
    "result = chain.invoke({\"transcript\": transcript, \"info_list\": \"Name, Years in company, Company, Salary, Notes, Next Actions\", \"job_description\": job_description_text})\n",
    "\n",
    "# Output the result\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
