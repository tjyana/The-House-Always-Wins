{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in ./venv/lib/python3.13/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.13/site-packages (from dotenv) (1.0.1)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.13/site-packages (0.3.19)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.37)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.10)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.13/site-packages (from langchain) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in ./venv/lib/python3.13/site-packages (from langchain) (2.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Collecting langchain_openai\n",
      "  Using cached langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in ./venv/lib/python3.13/site-packages (from langchain_openai) (0.3.37)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from langchain_openai)\n",
      "  Using cached openai-1.63.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (0.3.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.58.1->langchain_openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.58.1->langchain_openai)\n",
      "  Using cached jiter-0.8.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.58.1->langchain_openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./venv/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.35->langchain_openai) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.35->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.35->langchain_openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.35->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.35->langchain_openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n",
      "Using cached langchain_openai-0.3.6-py3-none-any.whl (54 kB)\n",
      "Using cached openai-1.63.2-py3-none-any.whl (472 kB)\n",
      "Downloading tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached jiter-0.8.2-cp313-cp313-macosx_11_0_arm64.whl (309 kB)\n",
      "Downloading regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, jiter, distro, tiktoken, openai, langchain_openai\n",
      "Successfully installed distro-1.9.0 jiter-0.8.2 langchain_openai-0.3.6 openai-1.63.2 regex-2024.11.6 tiktoken-0.9.0 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install dotenv\n",
    "!pip install requests\n",
    "!pip install langchain\n",
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elephants have complex social structures and are known for their strong familial bonds. Female elephants, also known as cows, tend to live in tight matriarchal family groups, which can consist of mothers, daughters, sisters, and their young ones. The matriarch, usually the oldest and largest female, leads the group and makes decisions regarding movement, protection, and the use of resources.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Define prompt templates (no need for separate Runnable chains)\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a facts expert who knows facts about {animal}.\"),\n",
    "        (\"human\", \"Tell me {fact_count} facts.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the combined chain using LangChain Expression Language (LCEL)\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "# chain = prompt_template | model\n",
    "\n",
    "# Run the chain\n",
    "result = chain.invoke({\"animal\": \"elephant\", \"fact_count\": 1})\n",
    "\n",
    "# Output\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recruiter (Alex): Hi [Candidate Name], thanks for connecting and taking the time to chat today. How are you doing?\n",
      "\n",
      "Candidate (Jordan): Hi Alex, I’m doing well, thank you. I appreciate you reaching out, and I’m eager to learn more about the opportunities you have available.\n",
      "\n",
      "Alex: Great to hear, Jordan. To start, I’d like to introduce myself. I’m Alex from Global Talent Partners—a recruitment agency that partners with several innovative companies here in Japan and internationally. I specialize in matching talented professionals with roles that align with their career goals. Could you share a bit about your background?\n",
      "\n",
      "Jordan: Absolutely. I’ve been in software development for about seven years now. I began my career as a junior developer in Japan and gradually moved into more senior roles. Currently, I work at ABC Tech in Tokyo, where I focus on backend development and cloud integration.\n",
      "\n",
      "Alex: That’s impressive. What initially drew you to backend development and cloud technologies? Was it a gradual shift, or did you have a clear interest from the start?\n",
      "\n",
      "Jordan: It was a mix of both. Early on, I was fascinated by the challenge of solving complex technical issues, and as I learned more, I recognized how critical robust backend systems and cloud solutions are for scaling applications. This naturally steered me toward roles where I could specialize further.\n",
      "\n",
      "Alex: Excellent. Could you walk me through what a typical day looks like for you at ABC Tech? What are your key responsibilities?\n",
      "\n",
      "Jordan: Sure. My day usually starts with a team stand-up where we review progress and address any blockers. I then dive into designing system architectures, managing a small team of developers, and ensuring that our cloud deployments run smoothly. I also coordinate with product and design teams—sometimes spanning different time zones—to ensure our technical solutions align with business needs.\n",
      "\n",
      "Alex: That sounds both challenging and rewarding. How would you describe the work culture at ABC Tech, especially given the blend of local practices and international collaboration?\n",
      "\n",
      "Jordan: The culture is very collaborative. There’s a strong emphasis on teamwork and continuous improvement. At the same time, because we work on international projects, we balance traditional Japanese work ethics—like punctuality and attention to detail—with modern agile practices that promote rapid innovation and feedback.\n",
      "\n",
      "Alex: That’s great insight. Given your current experience, what’s motivating you to explore new opportunities at this stage of your career?\n",
      "\n",
      "Jordan: While I’ve had a fulfilling experience at ABC Tech, I feel I’ve reached a point where I’m ready for new challenges. I’d like a role that offers more strategic involvement in product development and the chance to work on larger-scale, innovative projects. I’m eager to expand my skill set and contribute more broadly.\n",
      "\n",
      "Alex: Understood. Considering your aspirations, what kind of role are you looking for next? Are there particular responsibilities or types of projects that interest you?\n",
      "\n",
      "Jordan: I’m interested in a role that not only involves technical execution but also allows me to influence product direction. I’d love to work on projects that leverage cutting-edge cloud technologies and agile methodologies, and I’m also looking for an environment that values mentorship—where I can both learn from seasoned professionals and share my own experience.\n",
      "\n",
      "Alex: That makes sense. Let’s talk about some practical details. Can you share your current compensation and what your salary expectations are for your next move?\n",
      "\n",
      "Jordan: Currently, I’m earning about ¥12,000,000 per year. For my next role, I’d be looking for something in the range of ¥13,500,000 to ¥15,000,000, depending on the overall benefits and responsibilities.\n",
      "\n",
      "Alex: Thanks for clarifying that. Aside from salary, are there any other factors that are particularly important to you? For instance, work location, remote work flexibility, or specific benefits?\n",
      "\n",
      "Jordan: Location is key. Since I’m based in Tokyo, I’d prefer roles located there or that offer a hybrid model, which is respectful of local business culture. I also value opportunities for professional development, a good work-life balance, and a company culture that emphasizes open communication and continuous growth.\n",
      "\n",
      "Alex: It sounds like you have a clear vision for your next move. On the topic of culture, what kind of company values or attributes do you consider essential when evaluating a new opportunity?\n",
      "\n",
      "Jordan: I really value transparency, collaboration, and a commitment to innovation. I appreciate companies that honor both traditional business practices and modern, agile thinking. A supportive environment with clear paths for career progression and regular feedback is also very important to me.\n",
      "\n",
      "Alex: Excellent. Let’s shift gears a bit—could you describe a challenging project you’ve worked on recently? What was the challenge, and how did your team overcome it?\n",
      "\n",
      "Jordan: One project that stands out involved migrating a legacy system to a cloud-based solution. The main challenge was maintaining data consistency while minimizing downtime. We tackled it by breaking the migration into phases, performing thorough testing at each stage, and keeping continuous communication with all stakeholders. The phased approach paid off, and the project was ultimately successful, reinforcing the value of agile, incremental improvements.\n",
      "\n",
      "Alex: That’s a great example. How do you typically approach problem-solving in these complex scenarios? Is there a particular methodology you rely on?\n",
      "\n",
      "Jordan: I generally blend agile methodologies with lean principles. I break challenges into smaller tasks, focus on iterative testing, and actively seek feedback throughout the process. This approach minimizes risks and often leads to innovative solutions while keeping the team aligned.\n",
      "\n",
      "Alex: Very impressive. Since you’ve collaborated with international teams, how do you manage differences in time zones and cultural expectations?\n",
      "\n",
      "Jordan: Communication is key. I make sure to schedule overlapping work hours whenever possible and use digital collaboration tools to stay in sync. Being respectful and clear about expectations has been essential in bridging cultural differences and ensuring smooth cooperation.\n",
      "\n",
      "Alex: It’s clear you have a well-rounded approach. Now, before we wrap up, do you have any questions for me about the roles I’m recruiting for, the companies I work with, or our overall process?\n",
      "\n",
      "Jordan: Yes, I do. Could you tell me more about the types of companies you’re recruiting for, particularly how their team structures work and what kind of projects I might be involved with if I join one of them?\n",
      "\n",
      "Alex: Certainly. Our agency works with a diverse portfolio of companies—from established industry leaders to innovative startups. Typically, these companies have cross-functional teams that value collaboration. They use regular stand-ups, weekly sync-ups, and even team-building activities to ensure smooth communication, whether locally or across borders. In many cases, you’ll have the opportunity to work on projects that drive digital transformation and leverage advanced cloud solutions. Additionally, there are strong mentorship programs and clear career progression paths in place.\n",
      "\n",
      "Jordan: That sounds very promising. I’m also interested in learning about the hiring process. What should I expect in terms of next steps and any technical assessments?\n",
      "\n",
      "Alex: Generally, after our initial conversation, I’ll match you with roles that fit your profile and interests. For many positions, the process involves a technical interview with a team lead, followed by additional discussions with prospective colleagues. There might be a practical assessment depending on the role. I’ll guide you through each step to ensure the process is as transparent and efficient as possible.\n",
      "\n",
      "Jordan: I appreciate the clarity, Alex. That definitely makes me feel more confident about the process.\n",
      "\n",
      "Alex: Fantastic. I think we’ve covered a lot today. Is there anything else you’d like to discuss regarding your career goals or the opportunities we might have for you?\n",
      "\n",
      "Jordan: Not at the moment. I feel well-informed, and I’m excited about exploring roles that match my aspirations. Thank you for such a thorough conversation.\n",
      "\n",
      "Alex: My pleasure, Jordan. I’ll review the details we discussed and get back to you soon with some potential matches. Thank you again for your time and for sharing your experiences.\n",
      "\n",
      "Jordan: Thank you, Alex. I appreciate the opportunity to discuss my career and explore these new possibilities with your support. I look forward to hearing from you soon.\n",
      "\n",
      "Alex: Great. Have a wonderful day, and I’ll be in touch soon!\n",
      "\n",
      "Jordan: You too, Alex. Thanks again.\n"
     ]
    }
   ],
   "source": [
    "# read text file\n",
    "filename = \"data/Alex.txt\"\n",
    "with open(filename, \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jordan has been in the field of software development for about seven years. He began his career as a junior developer in Japan and gradually transitioned into more senior roles. Currently, he works at ABC Tech in Tokyo, specializing in backend development and cloud integration. Jordan's responsibilities include designing system architectures, managing a small team of developers, ensuring smooth cloud deployments, and coordinating with product and design teams across different time zones.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "\n",
    "\n",
    "# read text file\n",
    "filename = \"data/Alex.txt\"\n",
    "with open(filename, \"r\") as file:\n",
    "    transcript = file.read()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define prompt templates (no need for separate Runnable chains)\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant who has access to {transcript}.\"),\n",
    "        (\"human\", \"Tell me about candidate's {information}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the combined chain using LangChain Expression Language (LCEL)\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "# chain = prompt_template | model\n",
    "\n",
    "# Run the chain\n",
    "result = chain.invoke({\"transcript\": transcript, \"information\": \"work history\"})\n",
    "\n",
    "# Output format \n",
    "# we need Name, Years in company, Company, Notes\n",
    "# example output:\"name\": \"Alex\", \"years\":5,\"company\":\"Tech Corp\", \"notes\":\"Strong backend development background. Recently completed cloud certification.\" \n",
    "\n",
    "\n",
    "\n",
    "# Output\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"Jordan\",\n",
      "  \"years\": 7,\n",
      "  \"company\": \"ABC Tech\",\n",
      "  \"notes\": \"Focused on backend development and cloud integration. Manages a team of developers and coordinates internationally.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Read the text file containing the chat transcript\n",
    "filename = \"data/Alex.txt\"\n",
    "with open(filename, \"r\") as file:\n",
    "    transcript = file.read()\n",
    "\n",
    "# Define prompt templates. Note how we insert {information} into the human message.\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant who has access to the following transcript: {transcript}\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"Extract the candidate's {information} details from the transcript. \"\n",
    "                \"Return the result as a JSON object with the following keys: \"\n",
    "                \"'name' (string), 'years' (integer), 'company' (string), and 'notes' (string). \"\n",
    "                \"For example: {{'name': 'Alex', 'years': 5, 'company': 'Tech Corp', \"\n",
    "                \"'notes': 'Strong backend development background. Recently completed cloud certification.'}}\"\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the combined chain using LangChain Expression Language (LCEL)\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "# Run the chain. We pass in both the transcript and the specific information (\"work history\").\n",
    "result = chain.invoke({\"transcript\": transcript, \"information\": \"work history\"})\n",
    "\n",
    "# Output the result\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
